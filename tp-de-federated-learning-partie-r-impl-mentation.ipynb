{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch.nn as nn\nfrom torchvision import datasets, transforms\nimport random\nimport torch\nfrom torch.utils.data import DataLoader, Subset, random_split\nimport torch.optim as optim\nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:10:20.472552Z","iopub.execute_input":"2024-12-02T15:10:20.472948Z","iopub.status.idle":"2024-12-02T15:10:25.226739Z","shell.execute_reply.started":"2024-12-02T15:10:20.472911Z","shell.execute_reply":"2024-12-02T15:10:25.225808Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Load the MNIST dataset","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ntrain_dataset = datasets.MNIST(root='./', train=True, download=True, transform=transform)\ntest_dataset = datasets.MNIST(root='./', train=False, download=True, transform=transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:10:25.228902Z","iopub.execute_input":"2024-12-02T15:10:25.229434Z","iopub.status.idle":"2024-12-02T15:10:30.295440Z","shell.execute_reply.started":"2024-12-02T15:10:25.229391Z","shell.execute_reply":"2024-12-02T15:10:30.294536Z"}},"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 15877749.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 469194.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 4385234.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 2858293.89it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Extract two subsets of 600 data points each","metadata":{}},{"cell_type":"code","source":"random.seed(42)\n\nindices = list(range(len(train_dataset)))\nrandom.shuffle(indices)\n\n# Split into two subsets of 600 data points each\nsubset1_indices = indices[:600]\nsubset2_indices = indices[600:1200]\n\n# Create subset datasets\nsubset1 = torch.utils.data.Subset(train_dataset, subset1_indices)\nsubset2 = torch.utils.data.Subset(train_dataset, subset2_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:10:30.296650Z","iopub.execute_input":"2024-12-02T15:10:30.296932Z","iopub.status.idle":"2024-12-02T15:10:30.343952Z","shell.execute_reply.started":"2024-12-02T15:10:30.296905Z","shell.execute_reply":"2024-12-02T15:10:30.343089Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Create a simple Convolutional Neural Network","metadata":{}},{"cell_type":"code","source":"class SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(64 * 24 * 24, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:10:30.347008Z","iopub.execute_input":"2024-12-02T15:10:30.347335Z","iopub.status.idle":"2024-12-02T15:10:30.354592Z","shell.execute_reply.started":"2024-12-02T15:10:30.347306Z","shell.execute_reply":"2024-12-02T15:10:30.353742Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Create a function average_model_parameters","metadata":{}},{"cell_type":"code","source":"def average_model_parameters(models, average_weight):\n    averaged_params = {}\n    for param_name in models[0].state_dict():\n        avg_param = sum(weight * model.state_dict()[param_name] for weight, model in zip(average_weight, models))\n        averaged_params[param_name] = avg_param\n    return averaged_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:10:30.355836Z","iopub.execute_input":"2024-12-02T15:10:30.356113Z","iopub.status.idle":"2024-12-02T15:10:30.367150Z","shell.execute_reply.started":"2024-12-02T15:10:30.356088Z","shell.execute_reply":"2024-12-02T15:10:30.366298Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Create a function that updates","metadata":{}},{"cell_type":"code","source":"def update_model_parameters(model, averaged_params):\n    with torch.no_grad(): \n        for param_name, avg_param in averaged_params.items():\n            model.state_dict()[param_name].copy_(avg_param)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:10:30.368299Z","iopub.execute_input":"2024-12-02T15:10:30.368688Z","iopub.status.idle":"2024-12-02T15:10:30.379359Z","shell.execute_reply.started":"2024-12-02T15:10:30.368648Z","shell.execute_reply":"2024-12-02T15:10:30.378595Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Federated training function and evaluation","metadata":{}},{"cell_type":"code","source":"def federated_training(subset1, subset2, epochs=20, batch_size=50, average_weight=[0.5, 0.5], initialize_common_params=False):\n    model1 = SimpleCNN()\n    model2 = SimpleCNN()\n    criterion = nn.CrossEntropyLoss()\n    # With SGD optimizer, I get low accucary (0.1). So I choose Adam for better performance\n    optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n    optimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n\n    loader1 = DataLoader(subset1, batch_size=batch_size, shuffle=True)\n    loader2 = DataLoader(subset2, batch_size=batch_size, shuffle=True)\n\n    for epoch in range(epochs):\n        model1.train()\n        total_loss = 0\n        for images, labels in loader1:\n            optimizer1.zero_grad()\n            outputs = model1(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer1.step()\n            total_loss += loss.item()\n        \n        model2.train()\n        total_loss = 0\n        for images, labels in loader2:\n            optimizer2.zero_grad()\n            outputs = model2(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer2.step()\n            total_loss += loss.item()\n\n        if initialize_common_params:\n            # Average the model parameters\n            averaged_params = average_model_parameters([model1, model2], average_weight)\n            update_model_parameters(model1, averaged_params)\n            update_model_parameters(model2, averaged_params)\n\n    return model1, model2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:10:30.380670Z","iopub.execute_input":"2024-12-02T15:10:30.381061Z","iopub.status.idle":"2024-12-02T15:10:30.394257Z","shell.execute_reply.started":"2024-12-02T15:10:30.381020Z","shell.execute_reply":"2024-12-02T15:10:30.393363Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def evaluate_model(model, test_loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    return correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:10:30.395509Z","iopub.execute_input":"2024-12-02T15:10:30.395947Z","iopub.status.idle":"2024-12-02T15:10:30.410788Z","shell.execute_reply.started":"2024-12-02T15:10:30.395910Z","shell.execute_reply":"2024-12-02T15:10:30.409862Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Result","metadata":{}},{"cell_type":"code","source":"print(\"Training without initializing common parameters:\")\nmodel1, model2 = federated_training(subset1, subset2, epochs=20, batch_size=50, average_weight=[0.5, 0.5], initialize_common_params=False)\n\ntest_loader = DataLoader(test_dataset, batch_size=50, shuffle=False)\n\naccuracy_model1 = evaluate_model(model1, test_loader)\naccuracy_model2 = evaluate_model(model2, test_loader)\n\nprint(f\"Accuracy of model 1 (no common params): {accuracy_model1:.4f}\")\nprint(f\"Accuracy of model 2 (no common params): {accuracy_model2:.4f}\")\n\nprint(\"\\nTraining with initializing common parameters (Federated Averaging):\")\nmodel1, model2 = federated_training(subset1, subset2, epochs=20, batch_size=50, average_weight=[0.5, 0.5], initialize_common_params=True)\n\naccuracy_model1 = evaluate_model(model1, test_loader)\naccuracy_model2 = evaluate_model(model2, test_loader)\n\nprint(f\"Accuracy of model 1 (with common params): {accuracy_model1:.4f}\")\nprint(f\"Accuracy of model 2 (with common params): {accuracy_model2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:10:30.412232Z","iopub.execute_input":"2024-12-02T15:10:30.413001Z","iopub.status.idle":"2024-12-02T15:11:55.984924Z","shell.execute_reply.started":"2024-12-02T15:10:30.412963Z","shell.execute_reply":"2024-12-02T15:11:55.983976Z"}},"outputs":[{"name":"stdout","text":"Training without initializing common parameters:\nAccuracy of model 1 (no common params): 0.9028\nAccuracy of model 2 (no common params): 0.9091\n\nTraining with initializing common parameters (Federated Averaging):\nAccuracy of model 1 (with common params): 0.9262\nAccuracy of model 2 (with common params): 0.9262\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def find_minimum_data_points(train_dataset, test_dataset):\n    data_points_array = [100, 200, 300, 400, 500]\n    indices = list(range(len(train_dataset)))\n    random.shuffle(indices)\n    \n    for elem in data_points_array:\n        subset1_indices = indices[:elem]\n        subset2_indices = indices[elem:elem * 2]\n        subset1 = torch.utils.data.Subset(train_dataset, subset1_indices)\n        subset2 = torch.utils.data.Subset(train_dataset, subset2_indices)\n        model1, model2 = federated_training(subset1, subset2, epochs=20, batch_size=50, average_weight=[0.5, 0.5], initialize_common_params=True)\n\n        test_loader = DataLoader(test_dataset, batch_size=50, shuffle=False)\n        \n        accuracy_model1 = evaluate_model(model1, test_loader)\n        accuracy_model2 = evaluate_model(model2, test_loader)\n        \n        print(f\"Accuracy of model 1 with {elem} data points : {accuracy_model1:.4f}\")\n        print(f\"Accuracy of model 2 with {elem} data points : {accuracy_model2:.4f}\")\n    \n    return\n                \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:18:09.050037Z","iopub.execute_input":"2024-12-02T15:18:09.050770Z","iopub.status.idle":"2024-12-02T15:18:09.056988Z","shell.execute_reply.started":"2024-12-02T15:18:09.050735Z","shell.execute_reply":"2024-12-02T15:18:09.056005Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"find_minimum_data_points(train_dataset, test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:18:11.755007Z","iopub.execute_input":"2024-12-02T15:18:11.755744Z","iopub.status.idle":"2024-12-02T15:20:46.342970Z","shell.execute_reply.started":"2024-12-02T15:18:11.755709Z","shell.execute_reply":"2024-12-02T15:20:46.341994Z"}},"outputs":[{"name":"stdout","text":"Accuracy of model 1 with 100 data points : 0.2396\nAccuracy of model 2 with 100 data points : 0.2396\nAccuracy of model 1 with 200 data points : 0.2982\nAccuracy of model 2 with 200 data points : 0.2982\nAccuracy of model 1 with 300 data points : 0.3393\nAccuracy of model 2 with 300 data points : 0.3393\nAccuracy of model 1 with 400 data points : 0.3690\nAccuracy of model 2 with 400 data points : 0.3690\nAccuracy of model 1 with 500 data points : 0.3968\nAccuracy of model 2 with 500 data points : 0.3968\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"If we accept an accuracy of 90%, 400 data points is enough","metadata":{}},{"cell_type":"markdown","source":"## CIFAR-10","metadata":{}},{"cell_type":"code","source":"train_dataset = datasets.CIFAR10(root='./', train=True, download=True, transform=transform)\ntest_dataset = datasets.CIFAR10(root='./', train=False, download=True, transform=transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:13:57.815181Z","iopub.execute_input":"2024-12-02T15:13:57.815477Z","iopub.status.idle":"2024-12-02T15:14:04.645492Z","shell.execute_reply.started":"2024-12-02T15:13:57.815450Z","shell.execute_reply":"2024-12-02T15:14:04.644787Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:03<00:00, 49143547.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./cifar-10-python.tar.gz to ./\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"random.seed(42)\n\nindices = list(range(len(train_dataset)))\nrandom.shuffle(indices)\n\nsubset1_indices = indices[:600]\nsubset2_indices = indices[600:1200]\n\nsubset1 = torch.utils.data.Subset(train_dataset, subset1_indices)\nsubset2 = torch.utils.data.Subset(train_dataset, subset2_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:14:04.646615Z","iopub.execute_input":"2024-12-02T15:14:04.646884Z","iopub.status.idle":"2024-12-02T15:14:04.685582Z","shell.execute_reply.started":"2024-12-02T15:14:04.646860Z","shell.execute_reply":"2024-12-02T15:14:04.684651Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(64 * 28 * 28, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:14:04.686726Z","iopub.execute_input":"2024-12-02T15:14:04.686979Z","iopub.status.idle":"2024-12-02T15:14:04.692878Z","shell.execute_reply.started":"2024-12-02T15:14:04.686955Z","shell.execute_reply":"2024-12-02T15:14:04.691919Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"print(\"Training without initializing common parameters:\")\nmodel1, model2 = federated_training(subset1, subset2, epochs=40, batch_size=50, average_weight=[0.5, 0.5], initialize_common_params=False)\n\ntest_loader = DataLoader(test_dataset, batch_size=50, shuffle=False)\n\naccuracy_model1 = evaluate_model(model1, test_loader)\naccuracy_model2 = evaluate_model(model2, test_loader)\n\nprint(f\"Accuracy of model 1 (no common params): {accuracy_model1:.4f}\")\nprint(f\"Accuracy of model 2 (no common params): {accuracy_model2:.4f}\")\n\nprint(\"\\nTraining with initializing common parameters (Federated Averaging):\")\nmodel1, model2 = federated_training(subset1, subset2, epochs=40, batch_size=50, average_weight=[0.5, 0.5], initialize_common_params=True)\n\naccuracy_model1 = evaluate_model(model1, test_loader)\naccuracy_model2 = evaluate_model(model2, test_loader)\n\nprint(f\"Accuracy of model 1 (with common params): {accuracy_model1:.4f}\")\nprint(f\"Accuracy of model 2 (with common params): {accuracy_model2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:14:04.694275Z","iopub.execute_input":"2024-12-02T15:14:04.694811Z","iopub.status.idle":"2024-12-02T15:17:00.437667Z","shell.execute_reply.started":"2024-12-02T15:14:04.694771Z","shell.execute_reply":"2024-12-02T15:17:00.436385Z"}},"outputs":[{"name":"stdout","text":"Training without initializing common parameters:\nAccuracy of model 1 (no common params): 0.3446\nAccuracy of model 2 (no common params): 0.3491\n\nTraining with initializing common parameters (Federated Averaging):\nAccuracy of model 1 (with common params): 0.3969\nAccuracy of model 2 (with common params): 0.3969\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"find_minimum_data_points(train_dataset, test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T15:20:46.344911Z","iopub.execute_input":"2024-12-02T15:20:46.345320Z","iopub.status.idle":"2024-12-02T15:23:21.228652Z","shell.execute_reply.started":"2024-12-02T15:20:46.345255Z","shell.execute_reply":"2024-12-02T15:23:21.227752Z"}},"outputs":[{"name":"stdout","text":"Accuracy of model 1 with 100 data points : 0.2655\nAccuracy of model 2 with 100 data points : 0.2655\nAccuracy of model 1 with 200 data points : 0.2975\nAccuracy of model 2 with 200 data points : 0.2975\nAccuracy of model 1 with 300 data points : 0.3356\nAccuracy of model 2 with 300 data points : 0.3356\nAccuracy of model 1 with 400 data points : 0.3666\nAccuracy of model 2 with 400 data points : 0.3666\nAccuracy of model 1 with 500 data points : 0.3805\nAccuracy of model 2 with 500 data points : 0.3805\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"In CIFAR-10 study's, the accuracy is very lower than MNIST study's.\nIndeed CIFAR-10's images are more complex than MNIST's, then we should add more layers on the CNN architecture or using data augmentation in order to let model learn pattern more precisely.","metadata":{}}]}